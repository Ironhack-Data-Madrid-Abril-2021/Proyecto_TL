{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10dca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45d311d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"attacks.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b916d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/banking12/desktop/Proyecto_TL'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d7e73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/banking12/desktop/Proyecto_TL\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62da2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', '.gitignore.txt', '.ipynb_checkpoints', 'attacks.csv', 'Data_cleaning.ipynb', 'listado-de-pruebas.txt', 'sharks-clean2.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f936ef84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6307</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6309.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8702</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25722</th>\n",
       "      <td>xx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6312 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number         Date    Year        Type    Country  \\\n",
       "0      2018.06.25  25-Jun-2018  2018.0     Boating        USA   \n",
       "1      2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA   \n",
       "2      2018.06.09  09-Jun-2018  2018.0     Invalid        USA   \n",
       "3      2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA   \n",
       "4      2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO   \n",
       "...           ...          ...     ...         ...        ...   \n",
       "6307            0          NaN     NaN         NaN        NaN   \n",
       "6308            0          NaN     NaN         NaN        NaN   \n",
       "6309            0          NaN     NaN         NaN        NaN   \n",
       "8702          NaN          NaN     NaN         NaN        NaN   \n",
       "25722          xx          NaN     NaN         NaN        NaN   \n",
       "\n",
       "                  Area                        Location     Activity  \\\n",
       "0           California     Oceanside, San Diego County     Paddling   \n",
       "1              Georgia  St. Simon Island, Glynn County     Standing   \n",
       "2               Hawaii                    Habush, Oahu      Surfing   \n",
       "3      New South Wales              Arrawarra Headland      Surfing   \n",
       "4               Colima                        La Ticla  Free diving   \n",
       "...                ...                             ...          ...   \n",
       "6307               NaN                             NaN          NaN   \n",
       "6308               NaN                             NaN          NaN   \n",
       "6309               NaN                             NaN          NaN   \n",
       "8702               NaN                             NaN          NaN   \n",
       "25722              NaN                             NaN          NaN   \n",
       "\n",
       "                  Name Sex   ...         Species   \\\n",
       "0          Julie Wolfe    F  ...      White shark   \n",
       "1      Adyson McNeely     F  ...              NaN   \n",
       "2          John Denges    M  ...              NaN   \n",
       "3                 male    M  ...        2 m shark   \n",
       "4       Gustavo Ramos     M  ...  Tiger shark, 3m   \n",
       "...                ...  ...  ...              ...   \n",
       "6307               NaN  NaN  ...              NaN   \n",
       "6308               NaN  NaN  ...              NaN   \n",
       "6309               NaN  NaN  ...              NaN   \n",
       "8702               NaN  NaN  ...              NaN   \n",
       "25722              NaN  NaN  ...              NaN   \n",
       "\n",
       "               Investigator or Source                       pdf  \\\n",
       "0                    R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1      K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2      K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3                      B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4                           A .Kipper      2018.06.04-Ramos.pdf   \n",
       "...                               ...                       ...   \n",
       "6307                              NaN                       NaN   \n",
       "6308                              NaN                       NaN   \n",
       "6309                              NaN                       NaN   \n",
       "8702                              NaN                       NaN   \n",
       "25722                             NaN                       NaN   \n",
       "\n",
       "                                            href formula  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "...                                                  ...   \n",
       "6307                                                 NaN   \n",
       "6308                                                 NaN   \n",
       "6309                                                 NaN   \n",
       "8702                                                 NaN   \n",
       "25722                                                NaN   \n",
       "\n",
       "                                                    href Case Number.1  \\\n",
       "0      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4      http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "...                                                  ...           ...   \n",
       "6307                                                 NaN           NaN   \n",
       "6308                                                 NaN           NaN   \n",
       "6309                                                 NaN           NaN   \n",
       "8702                                                 NaN           NaN   \n",
       "25722                                                NaN           NaN   \n",
       "\n",
       "      Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0        2018.06.25         6303.0         NaN         NaN  \n",
       "1        2018.06.18         6302.0         NaN         NaN  \n",
       "2        2018.06.09         6301.0         NaN         NaN  \n",
       "3        2018.06.08         6300.0         NaN         NaN  \n",
       "4        2018.06.04         6299.0         NaN         NaN  \n",
       "...             ...            ...         ...         ...  \n",
       "6307            NaN         6309.0         NaN         NaN  \n",
       "6308            NaN         6310.0         NaN         NaN  \n",
       "6309            NaN            NaN         NaN         NaN  \n",
       "8702            NaN            NaN         NaN         NaN  \n",
       "25722           NaN            NaN         NaN         NaN  \n",
       "\n",
       "[6312 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing duplicated data not to double count\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2709f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"attacks.csv\", encoding='ISO-8859-1')\n",
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042730de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal (Y/N)</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and pad...</td>\n",
       "      <td>N</td>\n",
       "      <td>18h00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>Minor injury to left thigh</td>\n",
       "      <td>N</td>\n",
       "      <td>14h00  -15h00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Injury to left lower leg from surfboard skeg</td>\n",
       "      <td>N</td>\n",
       "      <td>07h45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Minor injury to lower leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lacerations to leg &amp; hand shark PROVOKED INCIDENT</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   Age  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F   57   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F   11   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M   48   \n",
       "3              Arrawarra Headland      Surfing             male    M  NaN   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  NaN   \n",
       "\n",
       "                                              Injury Fatal (Y/N)  \\\n",
       "0  No injury to occupant, outrigger canoe and pad...           N   \n",
       "1                         Minor injury to left thigh           N   \n",
       "2       Injury to left lower leg from surfboard skeg           N   \n",
       "3                          Minor injury to lower leg           N   \n",
       "4  Lacerations to leg & hand shark PROVOKED INCIDENT           N   \n",
       "\n",
       "            Time         Species           Investigator or Source  \\\n",
       "0          18h00      White shark                R. Collier, GSAF   \n",
       "1  14h00  -15h00              NaN  K.McMurray, TrackingSharks.com   \n",
       "2          07h45              NaN  K.McMurray, TrackingSharks.com   \n",
       "3            NaN        2 m shark                  B. Myatt, GSAF   \n",
       "4            NaN  Tiger shark, 3m                       A .Kipper   \n",
       "\n",
       "                        pdf  \\\n",
       "0      2018.06.25-Wolfe.pdf   \n",
       "1    2018.06.18-McNeely.pdf   \n",
       "2     2018.06.09-Denges.pdf   \n",
       "3  2018.06.08-Arrawarra.pdf   \n",
       "4      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2  original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25          6303.0         NaN         NaN  \n",
       "1    2018.06.18          6302.0         NaN         NaN  \n",
       "2    2018.06.09          6301.0         NaN         NaN  \n",
       "3    2018.06.08          6300.0         NaN         NaN  \n",
       "4    2018.06.04          6299.0         NaN         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df59b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b04fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25723, 24)\n",
      "Case Number                object\n",
      "Date                       object\n",
      "Year                      float64\n",
      "Type                       object\n",
      "Country                    object\n",
      "Area                       object\n",
      "Location                   object\n",
      "Activity                   object\n",
      "Name                       object\n",
      "Sex                        object\n",
      "Age                        object\n",
      "Injury                     object\n",
      "Fatal (Y/N)                object\n",
      "Time                       object\n",
      "Species                    object\n",
      "Investigator or Source     object\n",
      "pdf                        object\n",
      "href formula               object\n",
      "href                       object\n",
      "Case Number.1              object\n",
      "Case Number.2              object\n",
      "original order            float64\n",
      "Unnamed: 22                object\n",
      "Unnamed: 23                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#printing df shape and type of data, either numeric or categorical\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4a6066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number               17021\n",
       "Date                      19421\n",
       "Year                      19423\n",
       "Type                      19425\n",
       "Country                   19471\n",
       "Area                      19876\n",
       "Location                  19961\n",
       "Activity                  19965\n",
       "Name                      19631\n",
       "Sex                       19986\n",
       "Age                       22252\n",
       "Injury                    19449\n",
       "Fatal (Y/N)               19960\n",
       "Time                      22775\n",
       "Species                   22259\n",
       "Investigator or Source    19438\n",
       "pdf                       19421\n",
       "href formula              19422\n",
       "href                      19421\n",
       "Case Number.1             19421\n",
       "Case Number.2             19421\n",
       "original order            19414\n",
       "Unnamed: 22               25722\n",
       "Unnamed: 23               25721\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to assess validity of the data sum data in null columns\n",
    "null_cols = df.isnull().sum()\n",
    "null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af1bda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Number - 66%\n",
      "Date - 76%\n",
      "Year - 76%\n",
      "Type - 76%\n",
      "Country - 76%\n",
      "Area - 77%\n",
      "Location - 78%\n",
      "Activity - 78%\n",
      "Name - 76%\n",
      "Sex  - 78%\n",
      "Age - 87%\n",
      "Injury - 76%\n",
      "Fatal (Y/N) - 78%\n",
      "Time - 89%\n",
      "Species  - 87%\n",
      "Investigator or Source - 76%\n",
      "pdf - 76%\n",
      "href formula - 76%\n",
      "href - 76%\n",
      "Case Number.1 - 76%\n",
      "Case Number.2 - 76%\n",
      "original order - 75%\n",
      "Unnamed: 22 - 100%\n",
      "Unnamed: 23 - 100%\n"
     ]
    }
   ],
   "source": [
    "# since the data set contains a large number of elements we need to calculate % of data missing \n",
    "for col in df.columns:\n",
    "    pct_missing = np.mean(df[col].isnull())\n",
    "    print('{} - {}%'.format(col, round(pct_missing*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b773eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.', 'F', 'M', 'M ', 'N', 'lli', nan}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Sex '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3a5845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Sex ': 'Sex'}, inplace=True)\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba225fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the different categories shown by set inside 'Sex', \n",
    "#I will replace the unknown and rare values as shown below so that the only option becomes either Male or Female only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba2e7a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-500ec93ec656>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df['Sex'] = df['Sex'].str.replace('.', 'Unknown')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unknown    19988\n",
       "M           5098\n",
       "F            637\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sex'] = df['Sex'].str.replace('N', 'M')\n",
    "df['Sex'] = df['Sex'].str.strip()\n",
    "df['Sex'] = df['Sex'].fillna('Unknown')\n",
    "df['Sex'] = df['Sex'].str.replace('lli', 'Unknown')\n",
    "df['Sex'] = df['Sex'].str.replace('.', 'Unknown')\n",
    "set(df['Sex'])\n",
    "df['Sex'].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3ac08a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have applied the same formulas for Fatal (Y/N) \n",
    "#In order to eliminate errors and replace lower case values by capital letters to make the data set uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a115ecd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' N', '2017', 'M', 'N', 'N ', 'UNKNOWN', 'Y', nan, 'y'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set (df[(\"Fatal (Y/N)\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e27b75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'N', 'Y', 'U'}\n"
     ]
    }
   ],
   "source": [
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.strip()\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].fillna('U')\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.replace('y', 'Y')\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.replace('2017', 'U')\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.replace('M', 'U')\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.replace('F', 'Y')\n",
    "df[\"Fatal (Y/N)\"] = df[\"Fatal (Y/N)\"].str.replace('UNKNOWN', 'U')\n",
    "df.rename(columns={\"Fatal (Y/N)\": \"Fatal (Y/N)\"}, inplace=True)\n",
    "print(set(df[\"Fatal (Y/N)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02a4161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U    20033\n",
       "N     4301\n",
       "Y     1389\n",
       "Name: Fatal (Y/N), dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Fatal (Y/N)\"].describe()\n",
    "df[\"Fatal (Y/N)\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cda00664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To conduct my analysis I have decided to focus on the monthly time frame\n",
    "#Thus I  need the number of incidents pcm. \n",
    "#I use apply formula and regex to locate de month detail inside the Date colummn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d77f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date']=df['Date'].apply(str)\n",
    "month_lst = []\n",
    "for row in df['Date']:\n",
    "    month_row = ''.join(re.findall('\\-[A-Za-z]{3}\\-',row)).lower()\n",
    "    month_row = re.sub('\\-','',month_row)\n",
    "               \n",
    "    if month_row == '':\n",
    "        month_row = np.nan\n",
    "\n",
    "    month_lst.append(month_row)\n",
    "\n",
    "df['month'] = month_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b30d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided to use the if - elif statement below in order to fix length errors and replacing wrong characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d96a823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jul    621\n",
       "aug    556\n",
       "sep    521\n",
       "jan    494\n",
       "jun    475\n",
       "apr    420\n",
       "oct    417\n",
       "dec    415\n",
       "mar    381\n",
       "nov    378\n",
       "may    358\n",
       "feb    356\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['month'], inplace=True)\n",
    "for row in df['month']:\n",
    "    if len(row) > 3:\n",
    "        df['month'].replace(row,row[:3], inplace=True)\n",
    "    elif row == 'jut':\n",
    "        df['month'].replace(row,'jun', inplace=True)\n",
    "df['month'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70f147ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['Time'] == 'NaN'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd93ceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Afternoon        178\n",
       "11h00            119\n",
       "Morning          114\n",
       "15h00            106\n",
       "12h00            103\n",
       "                ... \n",
       "07h00 - 08h00      1\n",
       "09h00 -10h00       1\n",
       "Lunchtime          1\n",
       "11h57              1\n",
       "14h00 - 15h00      1\n",
       "Name: Time, Length: 359, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d7f6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping hours into four categories: Morning, Afternoon, Evening and Night\n",
    "#Extracted numbers from column: time, dropped na values and counted the values to see when did the shark attacks happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afba3af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0    248\n",
       "16.0    236\n",
       "15.0    235\n",
       "14.0    234\n",
       "12.0    197\n",
       "13.0    195\n",
       "17.0    192\n",
       "10.0    178\n",
       "18.0    129\n",
       "9.0     124\n",
       "8.0      92\n",
       "7.0      81\n",
       "19.0     53\n",
       "6.0      38\n",
       "20.0     29\n",
       "3.0      10\n",
       "5.0      10\n",
       "2.0       8\n",
       "23.0      8\n",
       "21.0      5\n",
       "4.0       5\n",
       "22.0      5\n",
       "1.0       5\n",
       "0.0       1\n",
       "Name: Clean_Hours, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_Hours'] = df['Time'].str.extract(\"([0-9]+)\", expand=False).dropna().astype(int)\n",
    "df['Clean_Hours']= df[df['Clean_Hours']<25]['Clean_Hours']\n",
    "df.drop(df[df['Clean_Hours'] == 'NaN'].index, inplace = True)\n",
    "df['Clean_Hours'].value_counts(dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb5a2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have grouped values in 4 sessions: 'Night', 'Morning', 'Afternoon', 'Evening'. I droped 0 and NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34f512bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Afternoon    1221\n",
       "Morning       920\n",
       "Evening       100\n",
       "Night          76\n",
       "Name: sessions, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [(df['Clean_Hours'] > 0.0) & (df['Clean_Hours'] <= 6.0),\n",
    "    (df['Clean_Hours'] > 6.0) & (df['Clean_Hours'] <= 12.0),\n",
    "    (df['Clean_Hours'] > 12.0) & (df['Clean_Hours'] <= 18.0),\n",
    "    (df['Clean_Hours'] > 18.0) & (df['Clean_Hours'] <= 23.0)]\n",
    "\n",
    "# creation of a list of the values we want to assign for each condition\n",
    "values = ['Night', 'Morning', 'Afternoon', 'Evening']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['sessions'] = np.select(conditions, values)\n",
    "df.drop(df[df['sessions'] == 'NaN'].index, inplace = True)\n",
    "df['sessions'].value_counts()\n",
    "df.drop(df[df['sessions'] == '0'].index, inplace = True)\n",
    "df['sessions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "100875d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      1991\n",
       "Provoked         121\n",
       "Invalid          103\n",
       "Boating           47\n",
       "Boat              29\n",
       "Sea Disaster      24\n",
       "Questionable       2\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c533ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Type\"] = df[\"Type\"].str.replace('Invalid', 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b7dafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have arranged the age column in order to know how many people I have from different ages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8192d7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     352\n",
       "19     93\n",
       "18     91\n",
       "15     78\n",
       "17     77\n",
       "     ... \n",
       "74      1\n",
       "3       1\n",
       "82      1\n",
       "75      1\n",
       "86      1\n",
       "Name: Age, Length: 75, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age=df['Age'].fillna('0')\n",
    "lst = []\n",
    "patron = '\\d+'\n",
    "for e in df.Age:\n",
    "    try:\n",
    "        lst.append(re.findall(patron,e)[0])\n",
    "    except:\n",
    "        lst.append(0)\n",
    "df.Age=lst\n",
    "\n",
    "df.Age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95ebf36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbd2e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Injury'] = df['Injury'].fillna('Unknown')\n",
    "\n",
    "df.Injury[df.Injury.str.contains('fatal')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('FATAL')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('fa')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('Fa')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('hark')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('ultiples')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('ajor')]='FATAL'\n",
    "df.Injury[df.Injury.str.contains('Sur')]='Survived'\n",
    "df.Injury[df.Injury.str.contains('vived')]='Survived'\n",
    "df.Injury[df.Injury.str.contains('Survived')]='Survived'\n",
    "df.Injury[df.Injury.str.contains('survived')]='Survived'\n",
    "df.Injury[df.Injury.str.contains('Foot')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('itten')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('oot')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('eg')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('ot')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('nee')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('3')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('eet')]='Foot bitten'\n",
    "df.Injury[df.Injury.str.contains('NO')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('no jury')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('no In')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('no jury')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('no Injury')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('no jury')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('No injury ')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('No Injury ')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('\"')]='No injury'\n",
    "df.Injury[df.Injury.str.contains(',')]='No injury'\n",
    "df.Injury[df.Injury.str.contains('aceration')]='Laceration'\n",
    "df.Injury[df.Injury.str.contains('rated')]='Laceration'\n",
    "df.Injury[df.Injury.str.contains('arm')]='Laceration'\n",
    "df.Injury[df.Injury.str.contains('humb')]='Laceration'\n",
    "df.Injury[df.Injury.str.contains('Left')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('rated')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('arm')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('humb')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('arm')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('humb')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('Hand')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('hand')]='Arm bitten'\n",
    "df.Injury[df.Injury.str.contains('2')]='Abrasion'\n",
    "df.Injury[df.Injury.str.contains('3')]='Abrasion'\n",
    "df.Injury[df.Injury.str.contains('Ab')]='Abrasion'\n",
    "df.Injury[df.Injury.str.contains('AB')]='Abrasion'\n",
    "df.Injury[df.Injury.str.contains('abrasion')]='Abrasion'\n",
    "df.Injury[df.Injury.str.contains('sion')]='Abrasion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a23961b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Provoked', 'Questionable', 'Sea Disaster', 'Unprovoked'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Following same formulas to rearrange Type Column\n",
    "df.Type = df.Type.fillna(\"Unknown\")\n",
    "df.Type[df.Type.str.contains(\"Boating\")] = 'Sea Disaster'\n",
    "df.Type[df.Type.str.contains(\"Boatomg\")] = 'Sea Disaster'\n",
    "df.Type[df.Type.str.contains(\"Boat\")] = 'Sea Disaster'\n",
    "df.Type[df.Type.str.contains(\"Invalid\")] = 'Unknown'\n",
    "df.Type[df.Type.str.contains(\"Boatomg\")] = 'Boat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e22498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the same formula to clear up Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06bb126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Country = df.Country.fillna(\"UNKNOWN\")\n",
    "df.Country[df.Country.str.contains('EGYPT')] = 'EGYPT'\n",
    "df.Country[df.Country.str.contains('ST HELENA, British overseas territory')] = 'ST HELENA'\n",
    "df.Country[df.Country.str.contains('nan}')] = 'UNKNOWN'\n",
    "df.Country[df.Country.str.contains('SOUTH ATLANTIC OCEAN')] = 'OTHERS'\n",
    "df.Country[df.Country.str.contains('ANDAMAN / NICOBAR ISLANDAS')] = 'OTHERS'\n",
    "df.Country[df.Country.str.contains('EGYPT / ISRAEL')] = 'OTHERS'\n",
    "df.Country[df.Country.str.contains('SOLOMON ISLANDS / VANUATU')] = 'OTHERS'\n",
    "df.Country[df.Country.str.contains('ATLANTIC OCEAN')] = 'OTHERS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d164e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I am going to clean the Area column \n",
    "df.Area = df.Area.fillna(\"Unknown\")\n",
    "df.Area[df.Area.str.contains(\"Southwestern Pacific\")] = 'Southwestern Pacific' \n",
    "df.Area[df.Area.str.contains(\"04.05N-13.23W\")] = 'Atlantic Ocean '\n",
    "df.Area[df.Area.str.contains(\"1,000 miles east of Hawaii\")] = 'Hawaii'\n",
    "df.Area[df.Area.str.contains(\"1000 miles west of Hawaii\")] = 'Hawaii'\n",
    "df.Area[df.Area.str.contains(\"10ºS, 142ºE\")] = 'Australia'\n",
    "df.Area[df.Area.str.contains(\"12 miles off the north coast'\")] = 'Unknown'\n",
    "df.Area[df.Area.str.contains(\"12 miles off the north coast'\")] = 'Unknown'\n",
    "df.Area[df.Area.str.contains(\"12 miles off the north coast\")] = 'Unknown'\n",
    "df.Area[df.Area.str.contains(\"180 miles southeast of Okinawa\")] = 'Okinawa'\n",
    "df.Area[df.Area.str.contains(\"165  miles from Bermuda\")] = 'Bermuda'\n",
    "df.Area[df.Area.str.contains(\"50 miles offshore\")] = 'Unknown'\n",
    "df.Area[df.Area.str.contains(\"18S / 50E\")] = 'Indian Ocean'\n",
    "df.Area[df.Area.str.contains(\"19S, 178?E\")] = 'Fiji'\n",
    "df.Area[df.Area.str.contains(\"2 to 3 miles off Taboguilla Island, Pacific Ocean\")] = 'Pacific Ocean'\n",
    "df.Area[df.Area.str.contains(\"Canary\")] = 'Canary Islands'\n",
    "df.Area[df.Area.str.contains(\"Manila\")] = 'Manila'\n",
    "df.Area[df.Area.str.contains(\"22ºN, 88ºE\")] = 'India'\n",
    "df.Area[df.Area.str.contains(\"25 km off the coast of Iran & 483km from mouth of Persian Gulf\")] = 'Iran'\n",
    "df.Area[df.Area.str.contains(\"Haw\")] = 'Hawaii'\n",
    "df.Area[df.Area.str.contains(\"Luzon\")] = 'Luzon'\n",
    "df.Area[df.Area.str.contains(\"Mauritius\")] = 'Mauritius'\n",
    "df.Area[df.Area.str.contains(\"Virgin Islands\")] = 'Virgin Islands'\n",
    "df.Area[df.Area.str.contains(\"Antigua\")] = 'Antigua'\n",
    "df.Area[df.Area.str.contains(\"Wake Island\")] = 'Wake Island'\n",
    "df.Area[df.Area.str.contains(\"Singapore\")] = 'Singapore'\n",
    "df.Area[df.Area.str.contains(\"33N, 68W\")] = 'Atlantic Ocean'\n",
    "df.Area[df.Area.str.contains(\"35º39 : 165º8\")] = 'Pacific Ocean'\n",
    "df.Area[df.Area.str.contains(\"40 miles south of Naples\")] = 'Naples'\n",
    "df.Area[df.Area.str.contains(\"40 miles off Grand Bahama Island\")] = 'Bahama Island'\n",
    "df.Area[df.Area.str.contains(\"Sri Lanka\")] = 'Sri Lanka'\n",
    "df.Area[df.Area.str.contains(\"5aint-Denis\")] = 'Saint-Denis'\n",
    "df.Area[df.Area.str.contains(\"Sri Lanka\")] = 'Sri Lanka'\n",
    "df.Area[df.Area.str.contains(\"San Domingo\")] = 'San Domingo'\n",
    "df.Area[df.Area.str.contains(\"740 miles SE of Tarawa Atoll\")] = 'Tarawa Atoll'\n",
    "df.Area[df.Area.str.contains(\"800 miles from land\")] = 'Unknown'\n",
    "df.Area[df.Area.str.contains(\"19S\")] = 'Fiji'\n",
    "df.Area[df.Area.str.contains(\"9.35N 79.35W\")] = 'Panama'\n",
    "df.Area[df.Area.str.contains(\"d\\x92Étang-Sal\")] = 'Unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "444577e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same applied to column species\n",
    "df.Species[df.Species.str.contains(\"White\")] = 'White shark'\n",
    "df.Species[df.Species.str.contains(\"white\")] = 'White shark'\n",
    "df.Species[df.Species.str.contains(\"Tiger\")] = 'Tiger shark'\n",
    "df.Species[df.Species.str.contains(\"tiger\")] = 'Tiger shark'\n",
    "df.Species[df.Species.str.contains(\"Bull\")] = 'Bull Shark'\n",
    "df.Species[df.Species.str.contains(\"bull\")] = 'Bull Shark'\n",
    "df.Species[df.Species.str.contains(\"Reef\")] = 'Reef shark'\n",
    "df.Species[df.Species.str.contains(\"reef\")] = 'Reef shark'\n",
    "df.Species[df.Species.str.contains(\"nurse\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"Nurse\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"grey\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"Grey\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"Gray\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"nurse\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"Nurse\")] = 'Grey nurse shark'\n",
    "df.Species[df.Species.str.contains(\"Blacktip\")] = 'Blacktip shark'\n",
    "df.Species[df.Species.str.contains(\"blacktip\")] = 'Blacktip shark'\n",
    "df.Species[df.Species.str.contains(\"Blue\")] = 'Blue shark'\n",
    "df.Species[df.Species.str.contains(\"blue\")] = 'Blue shark'\n",
    "df.Species[df.Species.str.contains(\"Bronze\")] = 'Bronze shark'\n",
    "df.Species[df.Species.str.contains(\"bronze\")] = 'Bronze shark'\n",
    "df.Species[df.Species.str.contains(\"hammerhead\")] = 'Hammerhead shark'\n",
    "df.Species[df.Species.str.contains(\"Hammerhead\")] = 'Hammerhead shark'\n",
    "df.Species[df.Species.str.contains(\"Lemon\")] = 'Lemon shark'\n",
    "df.Species[df.Species.str.contains(\"lemon\")] = 'Lemon shark'\n",
    "df.Species[df.Species.str.contains(\"Mako\")] = 'Mako shark'\n",
    "df.Species[df.Species.str.contains(\"mako\")] = 'Mako shark'\n",
    "df.Species[df.Species.str.contains(\"Dusky\")] = 'Dusky shark'\n",
    "df.Species[df.Species.str.contains(\"dusky\")] = 'Dusky shark'\n",
    "df.Species[df.Species.str.contains(\"Spinner\")] = 'Spinner shark'\n",
    "df.Species[df.Species.str.contains(\"spinner\")] = 'Spinner shark'\n",
    "df.Species[df.Species.str.contains(\"Wobbegong\")] = 'Wobbegong shark'\n",
    "df.Species[df.Species.str.contains(\"wobbegong\")] = 'Wobbegong shark'\n",
    "df.Species[df.Species.str.contains(\"raggedtooth\")] = 'Raggedtooth shark'\n",
    "df.Species[df.Species.str.contains(\"Raggedtooth\")] = 'Raggedtooth shark'\n",
    "df.Species[df.Species.str.contains(\"Sevengill\")] = 'Sevengill shark'\n",
    "df.Species[df.Species.str.contains(\"sevengill\")] = 'Sevengill shark'\n",
    "df.Species[df.Species.str.contains(\"Carpet\")] = 'Carpet shark'\n",
    "df.Species[df.Species.str.contains(\"carpet\")] = 'Carpet shark'\n",
    "df.Species[df.Species.str.contains(\"Porbeagle\")] = 'Porbeagle shark'\n",
    "df.Species[df.Species.str.contains(\"porbeagle\")] = 'Porbeagle shark'\n",
    "df.Species[df.Species.str.contains(\"Sand\")] = 'Sand shark'\n",
    "df.Species[df.Species.str.contains(\"sand\")] = 'Sand shark'\n",
    "df.Species[df.Species.str.contains(\"involvement\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"involve\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Remains\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"small\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"specified\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Possibly\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Questionable\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"authenticated\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Invalid\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"'\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"1\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"2\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"3\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"4\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"5\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"6\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"7\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"8\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"9\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"10\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"brown-colored\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"pack\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Attacked\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Dog\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"caught\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"large\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"black-tipped\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"dog\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"large\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"little\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"school\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"young\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"tipped\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"grey\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"gray\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"juvenile\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"whiptail\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"According\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Angel\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Blacktip\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Basking\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Blue\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Bronze\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Bull\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"leucas\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"maculpinnis\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Carpet\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Considered\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Doubtful\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Cookiecutter\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Copper\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Cow\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"drowning\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Description\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Dusky\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Fishermen\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Galapagos\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Goblin\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Hammerhead\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"gangeticus\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"eel\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"invovlement\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"invovlement\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"hoax\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"specified\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Porbeagle\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Raggedtooth\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Reef\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"story\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Salmon\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Sand\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Seven-gill\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"turtle\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"rough\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"specified\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Sevengill\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Shovelnose\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Silvertip\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Small\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Soupfin\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"unidentified\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Not\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Spinner\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Unidentified\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Thresher\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"recovered\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"Zambesi\")] = 'Not specified'\n",
    "df.Species[df.Species.str.contains(\"whaler\")] = 'Not specified'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5847719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted the file to a clean csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dd6657c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../Proyecto_TL/attacks_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
